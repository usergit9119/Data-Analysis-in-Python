{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36811669-96bf-4573-93d8-af027cc29384",
   "metadata": {},
   "source": [
    "<h1>Анализ данных в Python</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b23a74f-bcec-4ca3-a882-65fa9b8d7f90",
   "metadata": {},
   "source": [
    "<h2>Линейная регрессия</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcc35d-bf5e-4a21-8799-196f0d21a09b",
   "metadata": {},
   "source": [
    "<h3>Что такое Регрессия?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661170ca-575f-43fc-9150-9b74200467de",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><p>Регрессия ищет зависимость между переменными </p></li>\n",
    "    <li><p>регрессия помогает нам построить математическую модель, которая объединяет различные наблюдения в единое целое, что позволяет нам лучше понять взаимосвязи между переменными и использовать эти знания для прогнозирования.</p></li>\n",
    "    <li><p>Регрессия рассматривает некоторые наблюдения и ряд явлений. Каждое наблюдение имеет две и более переменных</p></li>\n",
    "    <li><p>Другими словами нужно найти функцию, которая отображает зависимость от одних переменных от других</p></li>\n",
    "    <li><p><b>Зависимые данные</b> называются зависимыми переменными, выходами или ответами.\n",
    "    <b>Независимые данные</b> называются независимыми переменными, входами или предсказателями.</p></li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4de8f9-46ed-437d-aa59-82b118a76aa4",
   "metadata": {},
   "source": [
    "<h3>Когда нужна Регрессия?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808100d9-fee5-4f02-bcb5-337ff27e5b60",
   "metadata": {},
   "source": [
    "<p>Регрессия полезна для прогнозирования ответа на новые условия. Можно угадать потребление электроэнергии в жилом доме из данных температуры, времени суток и количества жильцов.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d50c51-ef07-4d6d-938c-6a6f07b2019c",
   "metadata": {},
   "source": [
    "<h3>Постанковка проблемы</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63462e-5430-4bcc-8428-32a9859fe043",
   "metadata": {},
   "source": [
    "<p>Линейная регрессия представляет функцию y набор независимых переменных $x = (x_{1}, _{...}, x_{r})$, где r - число предсказателей, предполагает, что линейное отношение между y и x. Это и есть <b>Уравнение регрессии</b>: $$ y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_r x_r + \\varepsilon $$\n",
    "<ul>\n",
    "Где:\n",
    "    <li>$Y$ -зависимая переменная (целевая переменная)</li>\n",
    "    <li>$X_{1}, X_{2}, ..., X_{n}$ - независимые переменные (предикаторы)</li>\n",
    "    <li>$\\beta_0, \\beta_1, ... ,\\beta_n$ - коэффиценты регрессии,которые определяют влияние каждой независимой переменной на зависимую переменную. </li>\n",
    "    <li>$\\varepsilon$ - случайная ошибка, которая представляет расхождение между фактическими и прогнозируемыми значениями зависимой перменной</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4aa8a-a23e-4ddb-a639-a62298b6442b",
   "metadata": {},
   "source": [
    "<h4>Оценочные функции</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e63d2-c27e-44b8-978b-9e2b62463855",
   "metadata": {},
   "source": [
    "<p>Оценочная функция в контексте линейной регрессии используется для прогнозирования значений зависимой переменной на основе значений независимых переменных. В основе её использования лежат коэффициенты регрессии, которые были оценены в процессе обучения модели на обучающей выборке данных.<br>\n",
    "    Для прогнозирования значений зависимой переменной \n",
    "$Y$ для нового наблюдения $x$, мы подставляем соответствующие значения $x$ в оценочную функцию $f(x)$. Это даёт нам ожидаемое значение \n",
    "$Y$ на основе данных $x$ и параметров модели: $$Y_{predicted} = f(x) = b_{0} + b_{1}x_{1} + ... + b_{r}x_{r}$$\n",
    "Где:\n",
    "<ul> \n",
    "    <li>$Y_{predicted}$ - прогнозируемое значение</li>\n",
    "    <li>$x_{1},x_{2},...,x_{r}$ - значения независимых переменных для нового наблюдения.</li>\n",
    "    <li>$b_{0},b_{1},...,b_{r}$ - коэффиценты регрессии, оцененные в процессе обучения</li>\n",
    "    \n",
    "</ul>\n",
    "Таким образом, оценочная функция позволяет нам использовать модель линейной регрессии для прогнозирования значений зависимой переменной на основе новых данных, которые не были использованы при обучении модели. Это делает оценочную функцию полезным инструментом в анализе и прогнозировании данных.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db172e6-2e9c-44e1-a5e9-15a5b58802c6",
   "metadata": {},
   "source": [
    "<h4>Остаток регрессии</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee7825-54e9-45e0-ac04-49e5c831bfca",
   "metadata": {},
   "source": [
    "Для каждого результата наблюдения i = 1, ..., n, <b>Оценочный(предсказанный ответ)</b> $f(x_{i})$ ,должен быть как можно ближе к соответствующему <b>фактическому ответ</b> $y_{i}$. Разницы $y_{i} - f(x_{i})$ для всех результатов наблюдений называются <b>остатками</b>. Регрессия определяет лучшие <b>прогнозируемые весы измерения</b>, которые соответствуют наименьшими остаткам.\n",
    "\n",
    "в общем случае, чем меньше остаток регрессии, тем более точно модель линейной регрессии соответствует данным, и, следовательно, результат наблюдения может считаться более корректным. Остатки регрессии представляют собой разницу между фактическими значениями зависимой переменной и значениями, предсказанными моделью. Если остатки маленькие, это означает, что модель хорошо предсказывает или объясняет данные.\n",
    "\n",
    "Однако следует учитывать, что оценка корректности результатов наблюдения и модели зависит от контекста и целей исследования. Например, если остатки регрессии очень маленькие, это может указывать на переобучение модели, когда она слишком точно подстраивается под обучающие данные и неспособна обобщать на новые данные. В таких случаях модель может быть некорректной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa90995-8077-49ef-9ad0-b9be9cdfffde",
   "metadata": {},
   "source": [
    "<h4>Метод наименьших квадратов</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b224a2-dbea-4d5c-a3d7-9b6d5177720b",
   "metadata": {},
   "source": [
    "Для получения лучших весов, вам нужно минимизировать сумму остаточных квадратов (SSR) для всех результатов наблюдений. Этот подход называется <b>методом наименьших квадратов</b>.\n",
    "Метод наименьших квадратов (МНК) - это основной метод, используемый в линейной регрессии для оценки коэффициентов модели. Его цель состоит в том, чтобы найти такие коэффициенты $\\beta_{0},\\beta_{1},...,\\beta_{r}$, которые минимизируют сумму квадратов остатков, или разностей между фактическими и предсказанными значениями зависимой переменной.\n",
    "\n",
    "Вот шаги метода наименьших квадратов в линейной регрессии:\n",
    "<ol>\n",
    "    <li><b>Формулировка модели:</b>  Вы начинаете с формулировки модели линейной регрессии, которая представляет зависимость между зависимой переменной $y$ и независимыми переменными $x_{1},x_{2},...,x_{r}$. Выглядет это обычно так: $y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_r x_r + \\varepsilon$.</li>\n",
    "    <li><b>Оценка коэффицентов:</b>Задача состоит в том, чтобы найти такие значения коэффициентов $\\beta_{0},\\beta_{1},...,\\beta_{r}$, которые минимизируют сумму квадратов остатков. Формально, мы минимизируем функцию потерь: $$\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$</li>\n",
    "    <li><b>Решение уравнений:</b> Для нахождения оптимальных значений коэффициентов используются методы оптимизации, такие как градиентный спуск или аналитическое решение, которое можно найти путем дифференциации функции потерь по параметрам модели и приравнивании производных к нулю.</li>\n",
    "    <li><b>Оценка модели:</b> После нахождения оптимальных коэффициентов модель оценивается на тестовых данных, и её производительность проверяется с использованием различных метрик, таких как коэффициент детерминации $R^2$ или средняя квадратическая ошибка.</li> <br>\n",
    "<i>Метод наименьших квадратов широко используется из-за своей простоты и эффективности в оценке параметров линейной регрессии.</i>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be5bbf-6360-45e0-a317-7daa790b2410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7a063-7081-466b-921d-eac1dda2d583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
